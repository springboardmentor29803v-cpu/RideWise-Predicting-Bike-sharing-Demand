{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc712f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# PATHS\n",
    "# -----------------------------------------------------\n",
    "TEST_DATA_PATH = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Desktop\\\\INFOSYS\\\\Data\\\\dayTEST.csv\"\n",
    "TRAIN_PREPROCESSED_PATH = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Desktop\\\\INFOSYS\\\\Data\\\\preprocessed_day.csv\"\n",
    "\n",
    "SAVED_MODELS_DIR = \"./saved_models\"\n",
    "BEST_MODEL_DIR = \"./saved_models/bestModel\"\n",
    "SCALER_PATH = f\"{SAVED_MODELS_DIR}/scaler.pkl\"\n",
    "\n",
    "os.makedirs(BEST_MODEL_DIR, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a4bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest → RMSE: 1731.5625\n",
      "DecisionTree → RMSE: 1813.6385\n",
      "GradientBoost → RMSE: 3020.0204\n",
      "\n",
      " Best Model = RandomForest\n",
      "Best Model Saved at: ./saved_models/bestModel/RandomForest.pkl\n",
      "\n",
      " Showing first 20 prediction rows:\n",
      "\n",
      "    Actual_cnt  Predicted_cnt\n",
      "0          985        2247.61\n",
      "1          801        2322.08\n",
      "2         1349        2514.96\n",
      "3         1562        2532.45\n",
      "4         1600        2533.60\n",
      "5         1606        2533.66\n",
      "6         1510        2494.39\n",
      "7          959        2247.61\n",
      "8          822        2428.40\n",
      "9         1321        2514.96\n",
      "10        1263        2473.31\n",
      "11        1162        2533.60\n",
      "12        1406        2533.66\n",
      "13        1421        2543.16\n",
      "14        1248        2247.61\n",
      "15        1204        2428.40\n",
      "16        1000        2290.94\n",
      "17         683        2473.31\n",
      "18        1650        2476.08\n",
      "19        1927        2483.87\n",
      "\n",
      " Sample Predictions (first 10 rows):\n",
      "\n",
      "     Actual_cnt  Predicted_cnt\n",
      "26          431        2533.66\n",
      "27         1167        2494.39\n",
      "38         1530        2478.88\n",
      "52         1450        2478.88\n",
      "56         1969        2352.39\n",
      "107        3429        2744.17\n",
      "112        4036        2489.20\n",
      "127        4333        2683.10\n",
      "400        2947        5220.63\n",
      "409        3922        5132.16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. LOAD TEST DATA\n",
    "# -----------------------------------------------------\n",
    "df = pd.read_csv(TEST_DATA_PATH)\n",
    "actual_cnt = df[\"cnt\"].copy()\n",
    "\n",
    "# Drop columns not used in training\n",
    "df = df.drop([\"instant\", \"dteday\", \"casual\", \"registered\"], axis=1, errors=\"ignore\")\n",
    "\n",
    "# One-hot encode\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=[\"season\", \"mnth\", \"weekday\", \"weathersit\"],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. MATCH TRAINING FEATURE COLUMNS EXACTLY\n",
    "# -----------------------------------------------------\n",
    "train_df = pd.read_csv(TRAIN_PREPROCESSED_PATH)\n",
    "required_cols = train_df.drop(\"cnt\", axis=1).columns\n",
    "\n",
    "# Add missing columns\n",
    "for col in required_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0\n",
    "\n",
    "# Fix column order\n",
    "df = df[required_cols]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. APPLY SCALING\n",
    "# -----------------------------------------------------\n",
    "scaler = pickle.load(open(SCALER_PATH, \"rb\"))\n",
    "\n",
    "num_cols = [\"temp\", \"atemp\", \"hum\", \"windspeed\"]\n",
    "df[num_cols] = scaler.transform(df[num_cols])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. LOAD MODELS\n",
    "# -----------------------------------------------------\n",
    "model_paths = {\n",
    "    \"RandomForest\": f\"{SAVED_MODELS_DIR}/RandomForest.pkl\",\n",
    "    \"DecisionTree\": f\"{SAVED_MODELS_DIR}/DecisionTree.pkl\",\n",
    "    \"GradientBoost\": f\"{SAVED_MODELS_DIR}/GradientBoost.pkl\"\n",
    "}\n",
    "\n",
    "models = {name: pickle.load(open(path, \"rb\")) for name, path in model_paths.items()}\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. PREDICT WITH ALL MODELS\n",
    "# -----------------------------------------------------\n",
    "pred_results = {}\n",
    "rmse_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(df)\n",
    "    rmse = np.sqrt(mean_squared_error(actual_cnt, preds))\n",
    "\n",
    "    pred_results[name] = preds\n",
    "    rmse_scores[name] = rmse\n",
    "\n",
    "    print(f\"{name} → RMSE: {rmse:.4f}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. SELECT BEST MODEL\n",
    "# -----------------------------------------------------\n",
    "best_model_name = min(rmse_scores, key=rmse_scores.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\n Best Model = {best_model_name}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7. SAVE BEST MODEL\n",
    "# -----------------------------------------------------\n",
    "best_model_path = f\"{BEST_MODEL_DIR}/{best_model_name}.pkl\"\n",
    "pickle.dump(best_model, open(best_model_path, \"wb\"))\n",
    "\n",
    "print(f\"Best Model Saved at: {best_model_path}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 8. SAVE & SHOW PREDICTIONS\n",
    "# -----------------------------------------------------\n",
    "results = pd.DataFrame({\n",
    "    \"Actual_cnt\": actual_cnt,\n",
    "    \"Predicted_cnt\": pred_results[best_model_name]\n",
    "})\n",
    "\n",
    "print(\"\\n Showing first 20 prediction rows:\\n\")\n",
    "print(results.head(20))\n",
    "\n",
    "results.to_csv(\"./saved_models/bestModel/Predictions.csv\", index=False)\n",
    "print(\"\\n Sample Predictions (first 10 rows):\\n\")\n",
    "print(results.sample(10).sort_index())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
